function evaluate_model(model, X_test, Y_test)
    % EVALUATE_MODEL ุงุฑุฒุงุจ ุชุฎุตุต ุจุง ูุนุงุฑูุง ูพุฒุดฺฉ ู ูููุฏุงุฑ ROC
    
    disp(' ');
    disp('-----------------------------------------');
    disp('๐ ูุฑุญูู ณ: ุงุฑุฒุงุจ ูู ู ุชุฎุตุต (Technical Evaluation)');
    disp('-----------------------------------------');
    
    %% ฑ. ูพุดโุจู (ูู ฺฉูุงุณ ู ูู ุงุญุชูุงู)
    % ูุฏูโูุง ูพุดุฑูุชู ุนูุงูู ุจุฑ ฐ ู ฑุ ุฏุฑุตุฏ ุงุทููุงู (Score) ูู ูโุฏููุฏ
    [Y_pred, scores] = predict(model, X_test);
    
    %% ฒ. ุงุณุชุฎุฑุงุฌ ุงุนุฏุงุฏ ูุงุชุฑุณ ุฎุทุง
    cm = confusionmat(Y_test, Y_pred);
    % ฺุฏูุงู ูุงุชุฑุณ ุฏุฑ ูุชูุจ:
    % [TN  FP]
    % [FN  TP]
    TN = cm(1,1); % ุณุงูู ุฏุฑุณุช
    FP = cm(1,2); % ุณุงูู ุงุดุชุจุงู (ูุดุฏุงุฑ ุบูุท)
    FN = cm(2,1); % ุจูุงุฑ ุงุดุชุจุงู (ุฎุทุฑูุงฺฉ!)
    TP = cm(2,2); % ุจูุงุฑ ุฏุฑุณุช
    
    %% ณ. ูุญุงุณุจุงุช ุฑุงุถ (Formulas)
    
    % ุงูู) ุฏูุช ฺฉู (Accuracy): ฺูุฏุฑ ฺฉูุงู ุฏุฑุณุช ฺฏูุชูุ
    accuracy = (TP + TN) / sum(cm(:));
    
    % ุจ) ุญุณุงุณุช ุง ูุฑุงุฎูุงู (Recall / Sensitivity): ุงุฒ ุจู ุจูุงุฑุงูุ ฺูุฏ ุชุง ุฑู ฺฏุฑูุชูุ
    % ูุฑููู: TP / (TP + FN)
    recall = TP / (TP + FN);
    
    % ุฌ) ุฏูุชู ูพุดโุจู ูุซุจุช (Precision): ููุช ูฺฏู ูุฑุถูุ ฺูุฏุฑ ุงุญุชูุงู ุฏุงุฑู ูุงูุนุงู ูุฑุถ ุจุงุดูุ
    % ูุฑููู: TP / (TP + FP)
    precision = TP / (TP + FP);
    
    % ุฏ) ูฺฺฏ (Specificity): ุชูุงูุง ุชุดุฎุต ุณุงููโูุง
    % ูุฑููู: TN / (TN + FP)
    specificity = TN / (TN + FP);
    
    % ูู) ูุนุงุฑ F1-Score: ูุงูฺฏู ูุงุฑูููฺฉ ุจู Precision ู Recall
    % (ุจูุชุฑู ูุนุงุฑ ููุช ุฏุงุฏูโูุง ูุงูุชูุงุฒู ูุณุชูุฏ)
    f1_score = 2 * (precision * recall) / (precision + recall);
    
    %% ด. ููุงุด ฺฏุฒุงุฑุด ูุชู
    fprintf('%-25s | %-10s\n', 'Metric', 'Value');
    disp('---------------------------------------');
    fprintf('%-25s | %.2f%%\n', 'Accuracy (ุฏูุช ฺฉู)', accuracy * 100);
    fprintf('%-25s | %.2f%%\n', 'Recall (ูุฏุฑุช ฺฉุดู ุจูุงุฑ)', recall * 100);
    fprintf('%-25s | %.2f%%\n', 'Specificity (ุชุดุฎุต ุณุงูู)', specificity * 100);
    fprintf('%-25s | %.2f%%\n', 'Precision (ุงุทููุงู)', precision * 100);
    fprintf('%-25s | %.2f%%\n', 'F1-Score (ุงูุชุงุฒ ูู)', f1_score * 100);
    disp('---------------------------------------');
    fprintf('โ๏ธ ุฎุทุง ููุน ุฏูู (False Negative): %d ุจูุงุฑ ุชุดุฎุต ุฏุงุฏู ูุดุฏูุฏ.\n', FN);
    
    %% ต. ุฑุณู ูููุฏุงุฑ ROC (Receiver Operating Characteristic)
    % ุงู ูููุฏุงุฑ ูุดุงูโุฏููุฏู ุนููฺฉุฑุฏ ูุฏู ุฏุฑ ุขุณุชุงููโูุง ูุฎุชูู ุงุณุช
    % ูุฑฺูุฏุฑ ุฎุท ุขุจ ุจู ฺฏูุดู ุจุงูุง-ฺูพ ูุฒุฏฺฉโุชุฑ ุจุงุดุฏุ ูุฏู ุจูุชุฑ ุงุณุช.
    
    % ูุญุงุณุจู ููุงุท ูููุฏุงุฑ
    [Xroc, Yroc, ~, AUC] = perfcurve(Y_test, scores(:,2), 1);
    
    figure('Name', 'Evaluation Plots', 'Color', 'w', 'Position', [100, 100, 1000, 500]);
    
    % ูููุฏุงุฑ ุณูุช ฺูพ: Confusion Matrix
    subplot(1, 2, 1);
    confusionchart(Y_test, Y_pred, ...
        'Title', ['Confusion Matrix (Acc: ' num2str(accuracy*100, '%.1f') '%)'], ...
        'RowSummary', 'row-normalized');
        
    % ูููุฏุงุฑ ุณูุช ุฑุงุณุช: ROC Curve
    subplot(1, 2, 2);
    plot(Xroc, Yroc, 'LineWidth', 2.5, 'Color', [0, 0.4470, 0.7410]);
    hold on;
    plot([0, 1], [0, 1], '--k'); % ุฎุท ุชุตุงุฏู (ุดุฑ ุง ุฎุท)
    xlabel('False Positive Rate (1 - Specificity)');
    ylabel('True Positive Rate (Sensitivity)');
    title(['ROC Curve (AUC = ' num2str(AUC, '%.2f') ')']);
    grid on;
    legend(['AUC: ' num2str(AUC, '%.2f')], 'Random Guess', 'Location', 'SouthEast');
    
    disp('โ ูููุฏุงุฑูุง ุชุฎุตุต (ROC ู Confusion Matrix) ุฑุณู ุดุฏูุฏ.');
end