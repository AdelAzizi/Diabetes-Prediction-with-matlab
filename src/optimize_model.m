function finalModel = optimize_model(modelName, X_train, Y_train)
    % OPTIMIZE_MODEL Ù†Ø³Ø®Ù‡ Ø¨Ø¯ÙˆÙ† Ø¨Ø§Ú¯ Ùˆ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡
    
    disp(' ');
    disp(['ğŸ”§ Ø¯Ø± Ø­Ø§Ù„ ØªÛŒÙˆÙ†ÛŒÙ†Ú¯ Ù…Ø¯Ù„ ' modelName ' Ø¨Ø§ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø³Ø®Øªâ€ŒÚ¯ÛŒØ±Ø§Ù†Ù‡...']);
    
    %% Û±. Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ (Benchmark)
    % Ø§Ø¨ØªØ¯Ø§ Ù…Ø¯Ù„ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø±Ø§ Ù…ÛŒâ€ŒØ³Ø§Ø²ÛŒÙ…
    baseModel = fitcensemble(X_train, Y_train, 'Method', 'Bag');
    cvBase = crossval(baseModel, 'KFold', 5);
    baseLoss = kfoldLoss(cvBase);
    fprintf('   ğŸ“Š Ø®Ø·Ø§ÛŒ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ (Standard): %.4f\n', baseLoss);

    %% Û². ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¬Ø³ØªØ¬ÙˆÛŒ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§
    opts = struct('Optimizer', 'bayesopt', ...
                  'ShowPlots', false, ...      
                  'Verbose', 0, ...            
                  'AcquisitionFunctionName', 'expected-improvement-plus', ...
                  'MaxObjectiveEvaluations', 30); 

    if contains(modelName, 'Ensemble')
        
        % --- Ø§ØµÙ„Ø§Ø­ Ù…Ù‡Ù…: ØªØ¹Ø±ÛŒÙ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ù…ØªØºÛŒØ±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ Ø§Ø¨Ø¹Ø§Ø¯ ---
        
        % Û±. ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø±Ø®Øªâ€ŒÙ‡Ø§
        v1 = optimizableVariable('NumLearningCycles', [50, 500], 'Type', 'integer', 'Transform', 'log');
        
        % Û². Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ø±Ú¯ (Ù…Ø­Ø¯ÙˆØ¯ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø³Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ)
        v2 = optimizableVariable('MinLeafSize', [1, 5], 'Type', 'integer', 'Transform', 'none');
        
        % Û³. ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² size Ø¨Ù‡ Ø¬Ø§ÛŒ width Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ Ù…Ø§ØªØ±ÛŒØ³)
        numFeats = size(X_train, 2); 
        v3 = optimizableVariable('NumVariablesToSample', [1, numFeats], 'Type', 'integer', 'Transform', 'none');
        
        % ØªØ±Ú©ÛŒØ¨ Ù†Ù‡Ø§ÛŒÛŒ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§
        params = [v1, v2, v3];
        
        % -------------------------------------------------------------
        
        % Ø´Ø±ÙˆØ¹ Ø¬Ø³ØªØ¬Ùˆ
        resultsObj = fitcensemble(X_train, Y_train, ...
            'Method', 'Bag', ...
            'OptimizeHyperparameters', params, ...
            'HyperparameterOptimizationOptions', opts, ...
            'Learners', templateTree('Reproducible', true));
        
        bestParams = resultsObj.HyperparameterOptimizationResults.XAtMinObjective;
        minError = resultsObj.HyperparameterOptimizationResults.MinObjective;
        
        disp('ğŸ’ Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯:');
        disp(bestParams);
        
        %% Û³. ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ (The Smart Choice)
        % Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø®Ø·Ø§ÛŒ Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡
        
        if minError < baseLoss
            disp('âœ… Ù…Ø¯Ù„ ØªÛŒÙˆÙ† Ø´Ø¯Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù‡ØªØ±ÛŒ Ø¯Ø§Ø±Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Ø¨Ù‡ÛŒÙ†Ù‡...');
            finalModel = fitcensemble(X_train, Y_train, ...
                'Method', 'Bag', ...
                'NumLearningCycles', bestParams.NumLearningCycles, ...
                'Learners', templateTree('MinLeafSize', bestParams.MinLeafSize), ...
                'NPrint', 0);
        else
            disp('âš ï¸ Ù…Ø¯Ù„ ØªÛŒÙˆÙ† Ø´Ø¯Ù‡ Ù†ØªÙˆØ§Ù†Ø³Øª Ù…Ø¯Ù„ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø±Ø§ Ø´Ú©Ø³Øª Ø¯Ù‡Ø¯.');
            disp('â†©ï¸ Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ø¯Ù„ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ (Ú†ÙˆÙ† Ù†ØªÛŒØ¬Ù‡ Ø¨Ù‡ØªØ±ÛŒ Ø¯Ø§Ø±Ø¯).');
            finalModel = baseModel;
        end
            
    else
        % Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØºÛŒØ± Ensemble (Ù…Ø«Ù„ SVM)
        finalModel = fitcsvm(X_train, Y_train, 'Standardize', true);
    end
    
    disp('âœ… Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯.');
    disp('------------------------------------');
end